{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b21d0e-c0b5-4e65-8697-e03a92eaf9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/__init__.py:202: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n",
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/atlas.py:13: DeprecationWarning: ibllib.atlas.atlas.AllenAtlas is deprecated. Use iblatlas.atlas.AllenAtlas instead\n",
      "  warnings.warn(warning_text, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from one.api import ONE\n",
    "from brainbox.population.decode import get_spike_counts_in_bins\n",
    "from brainbox.io.one import SpikeSortingLoader, SessionLoader\n",
    "from brainbox.ephys_plots import plot_brain_regions\n",
    "from brainbox.behavior.wheel import velocity\n",
    "from brainbox.task.trials import get_event_aligned_raster, get_psth\n",
    "from ibllib.atlas import AllenAtlas\n",
    "from brainwidemap import bwm_query\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org', \\\n",
    "          password='international', silent=True)\n",
    "\n",
    "ba = AllenAtlas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fef67-b641-402f-b2e0-bbb169ecabcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bw = bwm_query()\n",
    "# print(df_bw.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6dba-c00a-4bcc-820f-f8c380f36a07",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65f888-6135-4648-8c6d-6c182380c421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Select your PID\n",
    "pid = '3675290c-8134-4598-b924-83edb7940269'\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Convert probe PID to session EID and probe name\n",
    "[eid, pname] = one.pid2eid(pid)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Load spike data\n",
    "ssl = SpikeSortingLoader(pid=pid, one=one, atlas=ba)\n",
    "spikes, clusters, channels = ssl.load_spike_sorting()\n",
    "clusters = ssl.merge_clusters(spikes, clusters, channels)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Restrict to only good clusters\n",
    "# Find the good cluster index:\n",
    "good_cluster_idx = clusters['label'] == 1\n",
    "good_cluster_IDs = clusters['cluster_id'][good_cluster_idx]\n",
    "# Filter the clusters accordingly:\n",
    "clusters_g = {key: val[good_cluster_idx] for key, val in clusters.items()}\n",
    "# Filter the spikes accordingly:\n",
    "good_spk_indx = np.where(np.isin(spikes['clusters'], good_cluster_IDs))\n",
    "spikes_g = {key: val[good_spk_indx] for key, val in spikes.items()}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# N neuronal units in total\n",
    "num_neuron = len(np.unique(spikes_g['clusters']))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Load trial data\n",
    "sl = SessionLoader(eid=eid, one=one)\n",
    "sl.load_trials()\n",
    "events = sl.trials['firstMovement_times']\n",
    "\n",
    "# If event == NaN, remove the trial from the analysis\n",
    "nan_index = np.where(np.isnan(events))[0]\n",
    "events = events.drop(index=nan_index).to_numpy()\n",
    "contrast_R = sl.trials.contrastRight.drop(index=nan_index).to_numpy()\n",
    "contrast_L = sl.trials.contrastLeft.drop(index=nan_index).to_numpy()\n",
    "choice = sl.trials.choice.drop(index=nan_index).to_numpy()\n",
    "block = sl.trials.probabilityLeft.drop(index=nan_index).to_numpy()\n",
    "\n",
    "# N trial count\n",
    "num_trial = len(events)\n",
    "\n",
    "# Find \"trials\" that go in one direction and the other direction\n",
    "# Note: This is not a pure indexing on the *task trials* as we removed trials with nan values previously\n",
    "indx_choice_a = np.where(choice == -1)[0]\n",
    "indx_choice_b = np.where(choice == 1)[0]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Load wheel data\n",
    "wheel = one.load_object(eid, 'wheel', collection='alf')\n",
    "speed = velocity(wheel.timestamps, wheel.position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df214486-a6fb-4dac-8284-5967374ba4f5",
   "metadata": {},
   "source": [
    "### analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7adb1b31-4501-4498-afd4-c6902b7de582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Select a time window of interest\n",
    "time_window = np.array([-0.1, 0.0])  # 100 ms before the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14736ee-4a54-473c-a308-201e1eedf670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Compute spike rate around event\n",
    "events_tw = np.array([events+time_window[0], events+time_window[1]]).T\n",
    "\n",
    "# Compute count (for all clusters of interest) (THIS CAN TAKE A WHILE)\n",
    "spike_count, cluster_id = get_spike_counts_in_bins(spikes_g['times'], spikes_g['clusters'], events_tw)\n",
    "\n",
    "# Compute rate (for all clusters of interest)\n",
    "spike_rate = np.zeros((num_neuron, num_trial))\n",
    "spike_rate = spike_count / (time_window[1] - time_window[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39c7bc-bdf1-4143-b54d-ea2467948a41",
   "metadata": {},
   "source": [
    "### decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b868a034-393f-4271-87b5-93af00d9a585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : 255 choice +1 / 410 trials\n",
      "Testing set : 224 choice +1 / 410 trials\n"
     ]
    }
   ],
   "source": [
    "# Check that there are indeed only 2 values in choice\n",
    "assert len(np.unique(choice)) == 2\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Use the spike count in the time window prior to the movement onset as predictors.\n",
    "# We use the same time window as defined earlier (Encoding)\n",
    "X = spike_count.T  # shape of spike_count : n units x n trials in set -> transpose to fit model\n",
    "y = choice\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Split trials into test and training sets for the logistic regression.\n",
    "# Take first half of trials for training, second half for testing (test_size = 0.5)\n",
    "#Â Fix random seed to repeat results across runs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# See how many trials there is for choice +1 ; -1\n",
    "print(f'Training set : {len(np.where(y_train == 1)[0])} choice +1 / {len(y_train)} trials')\n",
    "print(f'Testing set : {len(np.where(y_test == 1)[0])} choice +1 / {len(y_test)} trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41cf4d66-7b19-4828-a395-3ef70c4ec2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 293 trials correctly predicted / 410 trials\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# Fit the logistic regression model\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# Use the test set to assess the model accuracy\n",
    "choice_predicted = clf.predict(X_test)\n",
    "n_trial_correct = len(np.where(y_test == choice_predicted)[0])\n",
    "print(f'Accuracy : {n_trial_correct} trials correctly predicted / {len(y_test)} trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c238c6e1-75bc-448d-8e50-b8fee49c5940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/__init__.py:202: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SessionLoader\n",
    "\n",
    "from brainwidemap.bwm_loading import load_good_units, load_trials_and_mask, merge_probes\n",
    "from brainwidemap.decoding.functions.decoding import fit_eid\n",
    "from brainwidemap.decoding.functions.process_targets import load_behavior\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import params\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49149d96-19ba-4d65-9a32-2ebb37a2994e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54af1d9-ba62-4647-88dd-44038d49ac34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
