{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34812d8d-a1c4-4cab-a1c1-96b04fa8992b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/__init__.py:202: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SessionLoader\n",
    "\n",
    "from brainwidemap.bwm_loading import load_good_units, load_all_units, load_trials_and_mask, merge_probes\n",
    "from brainwidemap.decoding.functions.decoding import fit_eid\n",
    "from brainwidemap.decoding.functions.process_targets import load_behavior\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import params\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import RESULTS_DIR\n",
    "# from brainwidemap.decoding.settings_for_BWM_figure.settings_wheel_speed import params\n",
    "# from brainwidemap.decoding.settings_for_BWM_figure.settings_wheel_speed import RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06554af5-db49-4411-96d4-08bedf04551e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establish paths and filenames\n",
    "params['behfit_path'] = RESULTS_DIR.joinpath('decoding', 'results', 'behavioral')\n",
    "params['behfit_path'].mkdir(parents=True, exist_ok=True)\n",
    "params['neuralfit_path'] = RESULTS_DIR.joinpath('decoding', 'results', 'neural')\n",
    "params['neuralfit_path'].mkdir(parents=True, exist_ok=True)\n",
    "params['add_to_saving_path'] = (f\"_binsize={1000 * params['binsize']}_lags={params['n_bins_lag']}_\"\n",
    "                                f\"mergedProbes_{params['merged_probes']}\")\n",
    "imposter_file = RESULTS_DIR.joinpath('decoding', f\"imposterSessions_{params['target']}.pqt\")\n",
    "bwm_session_file = RESULTS_DIR.joinpath('decoding', 'bwm_cache_sessions.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6993fba-3688-4180-88e8-55779486553c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params[\"binsize\"] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf72fa6-501d-47d2-956d-e40a14081cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"binsize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f477db7-e72d-453a-b05e-488ebbcaecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ONE and bwm dataframe of sessions\n",
    "one = ONE(base_url=\"https://openalyx.internationalbrainlab.org\", mode='remote')\n",
    "bwm_df = pd.read_parquet(bwm_session_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122c19f3-db6a-4603-848d-9639201d6dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using a subset of bwm dataset\n"
     ]
    }
   ],
   "source": [
    "# Feature to run a subset of BWM dataset filtering by subjects.\n",
    "# To use this, add subject names to the end of the line that calls this script in 03_slurm*.sh.\n",
    "# See 03_slurm*.sh for an examples which is commented out or read the `03_*` section of the README.\n",
    "if len(sys.argv) > 2:\n",
    "    print('using a subset of bwm dataset')\n",
    "    #mysubs = [sys.argv[i] for i in range(2, len(sys.argv))]\n",
    "    #bwm_df = bwm_df[bwm_df[\"subject\"].isin(mysubs)]\n",
    "    myeids = [sys.argv[i] for i in range(2, len(sys.argv))]\n",
    "    # bwm_df = bwm_df[bwm_df[\"eid\"].isin(myeids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e3d346-0563-4674-8a66-20ccf57b6d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid = '3675290c-8134-4598-b924-83edb7940269'\n",
    "\n",
    "[eid, pname] = one.pid2eid(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e11fc78-8cea-44a0-bed6-f79e4cf2e8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09421c3d-bb08-4aac-b539-fbd51d767fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running merged probes for session eid: 56956777-dca5-468c-87cb-78150432cc57\n"
     ]
    }
   ],
   "source": [
    "if params['merged_probes']:\n",
    "    eid = bwm_df['eid'].unique()[idx]\n",
    "    tmp_df = bwm_df.set_index(['eid', 'subject']).xs(eid, level='eid')\n",
    "    subject = tmp_df.index[0]\n",
    "    pids = tmp_df['pid'].to_list()  # Select all probes of this session\n",
    "    probe_names = tmp_df['probe_name'].to_list()\n",
    "    print(f\"Running merged probes for session eid: {eid}\")\n",
    "else:\n",
    "    eid = bwm_df.iloc[idx]['eid']\n",
    "    subject = bwm_df.iloc[idx]['subject']\n",
    "    pid = bwm_df.iloc[idx]['pid']\n",
    "    probe_name = bwm_df.iloc[idx]['probe_name']\n",
    "    print(f\"Running probe pid: {pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28a7bc5-d8d5-4b86-84ab-2290d13c1444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['n_pseudo'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9e74f3-6f1a-4cda-8626-410600bfd3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load trials df\n",
    "sess_loader = SessionLoader(one, eid)\n",
    "sess_loader.load_trials()\n",
    "\n",
    "# create mask\n",
    "trials_df, trials_mask = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=params['min_rt'], max_rt=params['max_rt'],\n",
    "    min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "    exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "_, trials_mask_without_minrt = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=None, max_rt=params['max_rt'],\n",
    "    min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "    exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "_, trials_mask_without_maxrt = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=params['min_rt'], max_rt=None,\n",
    "    min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "    exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "_, trials_mask_withonly_nochoice = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=None, max_rt=None,\n",
    "    min_trial_len=None, max_trial_len=None,\n",
    "    exclude_nochoice=True, exclude_unbiased=False)\n",
    "\n",
    "params['trials_mask_diagnostics'] = [trials_mask,\n",
    "                                     trials_mask_without_minrt,\n",
    "                                     trials_mask_without_maxrt,\n",
    "                                     trials_mask_withonly_nochoice]\n",
    "\n",
    "# load target data if necessary (will probably put this into a function eventually)\n",
    "if params['target'] in ['wheel-vel', 'wheel-speed', 'l-whisker-me', 'r-whisker-me']:\n",
    "    # load target data\n",
    "    dlc_dict = load_behavior(params['target'], sess_loader)\n",
    "    # load imposter sessions\n",
    "    params['imposter_df'] = pd.read_parquet(imposter_file) if params['n_pseudo'] > 0 else None\n",
    "else:\n",
    "    dlc_dict = None\n",
    "    params['imposter_df'] = None\n",
    "\n",
    "# Load spike sorting data\n",
    "if params['merged_probes']:\n",
    "    clusters_list = []\n",
    "    spikes_list = []\n",
    "    for pid, probe_name in zip(pids, probe_names):\n",
    "        # tmp_spikes, tmp_clusters = load_good_units(one, pid, eid=eid, pname=probe_name)\n",
    "        tmp_spikes, tmp_clusters = load_all_units(one, pid, eid=eid, pname=probe_name)\n",
    "        tmp_clusters['pid'] = pid\n",
    "        spikes_list.append(tmp_spikes)\n",
    "        clusters_list.append(tmp_clusters)\n",
    "    spikes, clusters = merge_probes(spikes_list, clusters_list)\n",
    "else:\n",
    "    # spikes, clusters = load_good_units(one, pid, eid=eid, pname=probe_name)\n",
    "    spikes, clusters = load_all_units(one, pid, eid=eid, pname=probe_name)\n",
    "\n",
    "# Put everything into the input format fit_eid still expects at this point\n",
    "neural_dict = {\n",
    "    'spk_times': spikes['times'],\n",
    "    'spk_clu': spikes['clusters'],\n",
    "    'clu_regions': clusters['acronym'],\n",
    "    'clu_qc': {k: np.asarray(v) for k, v in clusters.to_dict('list').items()},\n",
    "    'clu_df': clusters\n",
    "}\n",
    "\n",
    "metadata = {\n",
    "    'subject': subject,\n",
    "    'eid': eid,\n",
    "    'probe_name': probe_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389748c7-460c-4467-9ecb-5d6b7c310466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f59567cb-3bff-4039-8d84-adda64ab0d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudo_ids = -np.ones(1).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c897f1d0-8987-4041-b475-1e81fa4e4f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import linear_model as sklm\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tqdm import tqdm\n",
    "from behavior_models.utils import format_data as format_data_mut\n",
    "from behavior_models.utils import format_input as format_input_mut\n",
    "\n",
    "from iblatlas.regions import BrainRegions\n",
    "\n",
    "from brainwidemap.decoding.functions.balancedweightings import balanced_weighting\n",
    "from brainwidemap.decoding.functions.process_inputs import build_predictor_matrix\n",
    "from brainwidemap.decoding.functions.process_inputs import select_ephys_regions\n",
    "from brainwidemap.decoding.functions.process_inputs import preprocess_ephys\n",
    "from brainwidemap.decoding.functions.process_targets import compute_beh_target\n",
    "from brainwidemap.decoding.functions.process_targets import compute_target_mask\n",
    "from brainwidemap.decoding.functions.process_targets import transform_data_for_decoding\n",
    "from brainwidemap.decoding.functions.process_targets import logisticreg_criteria\n",
    "from brainwidemap.decoding.functions.process_targets import get_target_data_per_trial_wrapper\n",
    "from brainwidemap.decoding.functions.utils import save_region_results\n",
    "from brainwidemap.decoding.functions.utils import get_save_path\n",
    "from brainwidemap.decoding.functions.nulldistributions import generate_null_distribution_session\n",
    "from brainwidemap.decoding.functions.process_targets import check_bhv_fit_exists\n",
    "from brainwidemap.decoding.functions.process_targets import optimal_Bayesian\n",
    "\n",
    "from brainwidemap.decoding.functions.decoding import decode_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bb8fb6e-8830-4b18-af80-17f6ca0b4f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on eid: 56956777-dca5-468c-87cb-78150432cc57\n"
     ]
    }
   ],
   "source": [
    "print(f'Working on eid: {metadata[\"eid\"]}')\n",
    "filenames = []  # this will contain paths to saved decoding results for this eid\n",
    "\n",
    "if kwargs['use_imposter_session'] and not kwargs['stitching_for_imposter_session']:\n",
    "    trials_df = trials_df[:int(kwargs['max_number_trials_when_no_stitching_for_imposter_session'])]\n",
    "\n",
    "if 0 in pseudo_ids:\n",
    "    raise ValueError(\n",
    "        'pseudo id can be -1 (actual session) or strictly greater than 0 (pseudo session)')\n",
    "\n",
    "if not np.all(np.sort(pseudo_ids) == pseudo_ids):\n",
    "    raise ValueError('pseudo_ids must be sorted')\n",
    "\n",
    "if kwargs['model'] == optimal_Bayesian and np.any(trials_df.probabilityLeft.values[:90] != 0.5):\n",
    "    raise ValueError(\n",
    "        'The optimal Bayesian model assumes 90 unbiased trials at the beginning of the '\n",
    "        'session, which is not the case here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "140beb72-f7ec-4988-accf-3e10354f546c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if is trained\n",
    "eids_train = (\n",
    "    [metadata['eid']] if 'eids_train' not in metadata.keys() else metadata['eids_train'])\n",
    "if 'eids_train' not in metadata.keys():\n",
    "    metadata['eids_train'] = eids_train\n",
    "elif metadata['eids_train'] != eids_train:\n",
    "    raise ValueError(\n",
    "        'eids_train are not supported yet. If you do not understand this error, '\n",
    "        'just take out the eids_train key in the metadata to solve it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e14d60c-3ba6-4e86-9ddf-7f52f3d4947c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m2023-11-06 18:16:59.878 INFO     [base_models.py:  289]   results found and loaded from /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/behavioral/NYU-11/model_actKernel_single_zeta/train_56956777.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if isinstance(kwargs['model'], str):\n",
    "    import pickle\n",
    "    from braindelphi.params import INTER_INDIVIDUAL_PATH\n",
    "    inter_individual = pickle.load(open(INTER_INDIVIDUAL_PATH.joinpath(kwargs['model']), 'rb'))\n",
    "    if metadata['eid'] not in inter_individual.keys():\n",
    "        logging.exception('no inter individual model found')\n",
    "        print(filenames)\n",
    "    inter_indiv_model_specifications = inter_individual[metadata['eid']]\n",
    "    print('winning interindividual model is %s' % inter_indiv_model_specifications['model_name'])\n",
    "    if inter_indiv_model_specifications['model_name'] not in kwargs['modeldispatcher'].values():\n",
    "        logging.exception('winning inter individual model is LeftKernel or RightKernel')\n",
    "        print(filenames)\n",
    "    kwargs['model'] = {v: k for k, v in kwargs['modeldispatcher'].items()}[inter_indiv_model_specifications['model_name']]\n",
    "    kwargs['model_parameters'] = inter_indiv_model_specifications['model_parameters']\n",
    "else:\n",
    "    kwargs['model_parameters'] = None\n",
    "    # train model if not trained already\n",
    "    if kwargs['model'] != optimal_Bayesian and kwargs['model'] is not None:\n",
    "        side, stim, act, _ = format_data_mut(trials_df)\n",
    "        stimuli, actions, stim_side = format_input_mut([stim], [act], [side])\n",
    "        behmodel = kwargs['model'](\n",
    "            kwargs['behfit_path'], np.array(metadata['eids_train']), metadata['subject'],\n",
    "            actions, stimuli, trials_df, stim_side, single_zeta=True)\n",
    "        istrained, _ = check_bhv_fit_exists(\n",
    "            metadata['subject'], kwargs['model'], metadata['eids_train'],\n",
    "            kwargs['behfit_path'], modeldispatcher=kwargs['modeldispatcher'], single_zeta=True)\n",
    "        if not istrained:\n",
    "            behmodel.load_or_train(remove_old=False)\n",
    "\n",
    "if kwargs['balanced_weight'] and kwargs['balanced_continuous_target']:\n",
    "    raise NotImplementedError(\"see tag `decoding_biasCWnull` for a previous implementation.\")\n",
    "else:\n",
    "    target_distribution = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b85388-7082-4ca2-a047-4ffab5a38136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get target values\n",
    "if kwargs['target'] in ['pLeft', 'signcont', 'strengthcont', 'choice', 'feedback']:\n",
    "    target_vals_list, target_vals_to_mask = compute_beh_target(\n",
    "        trials_df, metadata, return_raw=True, **kwargs)\n",
    "    target_mask = compute_target_mask(\n",
    "        target_vals_to_mask, kwargs['exclude_trials_within_values'])\n",
    "\n",
    "else:\n",
    "    if dlc_dict is None or dlc_dict['times'] is None or dlc_dict['values'] is None:\n",
    "        raise ValueError('dlc_dict does not contain any data')\n",
    "    _, target_vals_list, target_mask = get_target_data_per_trial_wrapper(\n",
    "        target_times=dlc_dict['times'],\n",
    "        target_vals=dlc_dict['values'],\n",
    "        trials_df=trials_df,\n",
    "        align_event=kwargs['align_time'],\n",
    "        align_interval=kwargs['time_window'],\n",
    "        binsize=kwargs['binsize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5e4484-cb81-49f2-9ae2-a32e8b1b4bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = trials_mask & target_mask\n",
    "\n",
    "if sum(mask) <= kwargs['min_behav_trials']:\n",
    "    msg = 'session contains %i trials, below the threshold of %i' % (\n",
    "        sum(mask), kwargs['min_behav_trials'])\n",
    "    logging.exception(msg)\n",
    "    print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01a700b8-af4e-434e-95dc-ccd2a7175836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select brain regions from beryl atlas to loop over\n",
    "brainreg = BrainRegions()\n",
    "beryl_reg = brainreg.acronym2acronym(neural_dict['clu_regions'], mapping='Beryl')\n",
    "regions = (\n",
    "    [[k] for k in np.unique(beryl_reg)] if kwargs['single_region'] else [np.unique(beryl_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee1f8d89-90ce-406f-b477-fa69faaa589b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs['n_runs'] = 1\n",
    "\n",
    "trial_len = kwargs['time_window'][1] - kwargs['time_window'][0]\n",
    "binsize = kwargs.get('binsize', trial_len)\n",
    "    \n",
    "# kwargs['n_bins_lag'] = int(trial_len // binsize)\n",
    "kwargs['n_bins_lag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac8b5463-c74b-4c34-b763-a6f277c3f261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudo_id = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f95cb70-d2f5-4e49-b661-1002cd894763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebfa171e-b84d-4374-aa75-5e93b0880caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 56956777-dca5-468c-87cb-78150432cc57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "region_results = {}\n",
    "for region in tqdm(regions, desc='Region: ', leave=False):\n",
    "\n",
    "    # pull spikes from this region out of the neural data\n",
    "    reg_clu_ids = select_ephys_regions(neural_dict, beryl_reg, region, **kwargs)\n",
    "\n",
    "    # skip region if there are not enough units\n",
    "    n_units = len(reg_clu_ids)\n",
    "    if n_units < kwargs['min_units']:\n",
    "        continue\n",
    "\n",
    "    # bin spikes from this region for each trial\n",
    "    msub_binned, cl_inds_used = preprocess_ephys(reg_clu_ids, neural_dict, trials_df, **kwargs)\n",
    "    cl_uuids_used = list(neural_dict['clu_df'].iloc[cl_inds_used]['uuids'])\n",
    "\n",
    "    # make design matrix\n",
    "    bins_per_trial = msub_binned[0].shape[0]\n",
    "    Xs = (\n",
    "        msub_binned if bins_per_trial == 1\n",
    "        else [build_predictor_matrix(s, kwargs['n_bins_lag']) for s in msub_binned]\n",
    "    )\n",
    "    \n",
    "    control_mask = mask\n",
    "    save_predictions = kwargs['save_predictions']\n",
    "\n",
    "    # original session\n",
    "    ys_wmask = [target_vals_list[m] for m in np.squeeze(np.where(mask))]\n",
    "    Xs_wmask = [Xs[m] for m in np.squeeze(np.where(mask))]\n",
    "    \n",
    "    fit_results = []\n",
    "    for i_run in range(kwargs['n_runs']):\n",
    "\n",
    "        # set seed for reproducibility\n",
    "        rng_seed = i_run\n",
    "\n",
    "        fit_result = decode_cv(\n",
    "            ys=ys_wmask,\n",
    "            Xs=Xs_wmask,\n",
    "            estimator=kwargs['estimator'],\n",
    "            use_openturns=kwargs['use_openturns'],\n",
    "            target_distribution=target_distribution,\n",
    "            balanced_continuous_target=kwargs['balanced_continuous_target'],\n",
    "            estimator_kwargs=kwargs['estimator_kwargs'],\n",
    "            hyperparam_grid=kwargs['hyperparam_grid'],\n",
    "            save_binned=kwargs['save_binned'] if pseudo_id == -1 else False,\n",
    "            save_predictions=save_predictions,\n",
    "            shuffle=kwargs['shuffle'],\n",
    "            balanced_weight=kwargs['balanced_weight'],\n",
    "            rng_seed=rng_seed,\n",
    "        )\n",
    "        fit_result['mask'] = mask\n",
    "        fit_result['mask_trials_and_targets'] = [trials_mask, target_mask]\n",
    "        fit_result['mask_diagnostics'] = kwargs['trials_mask_diagnostics']\n",
    "        fit_result['df'] = trials_df if pseudo_id == -1 else controlsess_df\n",
    "        fit_result['pseudo_id'] = pseudo_id\n",
    "        fit_result['run_id'] = i_run\n",
    "        fit_result['cluster_uuids'] = cl_uuids_used\n",
    "        fit_results.append(fit_result)\n",
    "        \n",
    "    region_results.update({region[0]: fit_results[0]['acc_test_full']})\n",
    "\n",
    "        \n",
    "print(f'Finished eid: {metadata[\"eid\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1353a062-41e5-4561-85d9-2f2a60136bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMA': 0.6244897959183674,\n",
       " 'CA1': 0.6,\n",
       " 'CA2': 0.5428571428571428,\n",
       " 'CA3': 0.5918367346938775,\n",
       " 'CEA': 0.6040816326530613,\n",
       " 'COAp': 0.8081632653061225,\n",
       " 'GPe': 0.7020408163265306,\n",
       " 'IA': 0.6204081632653061,\n",
       " 'LGd': 0.7510204081632653,\n",
       " 'PA': 0.46530612244897956,\n",
       " 'SSp-bfd': 0.6,\n",
       " 'SSp-tr': 0.6285714285714286,\n",
       " 'VISa': 0.5755102040816327,\n",
       " 'VPM': 0.5755102040816327,\n",
       " 'root': 0.7510204081632653,\n",
       " 'void': 0.6204081632653061}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no time binning\n",
    "region_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a496e3e-c31e-4848-baa8-63bd7f840c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMA': 0.5142857142857142,\n",
       " 'CA1': 0.5714285714285714,\n",
       " 'CA2': 0.5755102040816327,\n",
       " 'CA3': 0.5387755102040817,\n",
       " 'CEA': 0.5387755102040817,\n",
       " 'COAp': 0.8,\n",
       " 'GPe': 0.6408163265306123,\n",
       " 'IA': 0.5551020408163265,\n",
       " 'LGd': 0.726530612244898,\n",
       " 'PA': 0.5346938775510204,\n",
       " 'SSp-bfd': 0.6,\n",
       " 'SSp-tr': 0.6612244897959184,\n",
       " 'VISa': 0.5591836734693878,\n",
       " 'VPM': 0.6040816326530613,\n",
       " 'root': 0.710204081632653,\n",
       " 'void': 0.6081632653061224}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.02 time bin\n",
    "region_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54af1d9-ba62-4647-88dd-44038d49ac34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
