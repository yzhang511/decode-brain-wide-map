{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34812d8d-a1c4-4cab-a1c1-96b04fa8992b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/__init__.py:202: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SessionLoader\n",
    "from iblatlas.regions import BrainRegions\n",
    "\n",
    "from sklearn import linear_model as sklm\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from behavior_models.utils import format_data as format_data_mut\n",
    "from behavior_models.utils import format_input as format_input_mut\n",
    "\n",
    "from brainwidemap.bwm_loading import load_good_units, load_trials_and_mask, merge_probes\n",
    "from brainwidemap.decoding.functions.process_targets import load_behavior\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import params\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import RESULTS_DIR\n",
    "\n",
    "from brainwidemap.decoding.functions.balancedweightings import balanced_weighting\n",
    "from brainwidemap.decoding.functions.process_inputs import (\n",
    "    build_predictor_matrix,\n",
    "    select_ephys_regions,\n",
    "    preprocess_ephys\n",
    ")\n",
    "from brainwidemap.decoding.functions.process_targets import (\n",
    "    compute_beh_target,\n",
    "    compute_target_mask,\n",
    "    transform_data_for_decoding,\n",
    "    logisticreg_criteria,\n",
    "    get_target_data_per_trial_wrapper,\n",
    "    check_bhv_fit_exists,\n",
    "    optimal_Bayesian\n",
    ")\n",
    "from brainwidemap.decoding.functions.utils import save_region_results, get_save_path\n",
    "from brainwidemap.decoding.functions.nulldistributions import generate_null_distribution_session\n",
    "from brainwidemap.decoding.functions.decoding import decode_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4976e-a2b4-4ab6-8576-f220e9bd572f",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06554af5-db49-4411-96d4-08bedf04551e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['behfit_path'] = RESULTS_DIR.joinpath('decoding', 'results', 'behavioral')\n",
    "params['behfit_path'].mkdir(parents=True, exist_ok=True)\n",
    "params['neuralfit_path'] = RESULTS_DIR.joinpath('decoding', 'results', 'neural')\n",
    "params['neuralfit_path'].mkdir(parents=True, exist_ok=True)\n",
    "params['add_to_saving_path'] = (f\"_binsize={1000 * params['binsize']}_lags={params['n_bins_lag']}_\"\n",
    "                                f\"mergedProbes_{params['merged_probes']}\")\n",
    "imposter_file = RESULTS_DIR.joinpath('decoding', f\"imposterSessions_{params['target']}.pqt\")\n",
    "bwm_session_file = RESULTS_DIR.joinpath('decoding', 'bwm_cache_sessions.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1316757c-d3ca-48bc-9bf4-67c06d296821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstMovement_times\n"
     ]
    }
   ],
   "source": [
    "# params[\"align_time\"] = \"stimOn_times\"\n",
    "print(params[\"align_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910af896-fb9c-45e8-9ac1-7856e7c304c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.1, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# params[\"time_window\"] = (0., 1.5)\n",
    "print(params[\"time_window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6993fba-3688-4180-88e8-55779486553c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "params[\"binsize\"] = 0.02 #0.1\n",
    "print(params[\"binsize\"])\n",
    "params['n_pseudo'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f477db7-e72d-453a-b05e-488ebbcaecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one = ONE(base_url=\"https://openalyx.internationalbrainlab.org\", mode='remote')\n",
    "bwm_df = pd.read_parquet(bwm_session_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09421c3d-bb08-4aac-b539-fbd51d767fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "if params['merged_probes']:\n",
    "    eid = bwm_df['eid'].unique()[idx]\n",
    "    tmp_df = bwm_df.set_index(['eid', 'subject']).xs(eid, level='eid')\n",
    "    subject = tmp_df.index[0]\n",
    "    pids = tmp_df['pid'].to_list()  # Select all probes of this session\n",
    "    probe_names = tmp_df['probe_name'].to_list()\n",
    "    print(f\"Running merged probes for session eid: {eid}\")\n",
    "else:\n",
    "    eid = bwm_df.iloc[idx]['eid']\n",
    "    subject = bwm_df.iloc[idx]['subject']\n",
    "    pid = bwm_df.iloc[idx]['pid']\n",
    "    probe_name = bwm_df.iloc[idx]['probe_name']\n",
    "    print(f\"Running probe pid: {pid}\")\n",
    "    \n",
    "sess_loader = SessionLoader(one, eid)\n",
    "sess_loader.load_trials()\n",
    "\n",
    "trials_df, trials_mask = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=params['min_rt'], max_rt=params['max_rt'],\n",
    "    min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "    exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "_, trials_mask_without_minrt = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=None, max_rt=params['max_rt'],\n",
    "    min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "    exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "_, trials_mask_without_maxrt = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=params['min_rt'], max_rt=None,\n",
    "    min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "    exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "_, trials_mask_withonly_nochoice = load_trials_and_mask(\n",
    "    one=one, eid=eid, sess_loader=sess_loader, min_rt=None, max_rt=None,\n",
    "    min_trial_len=None, max_trial_len=None,\n",
    "    exclude_nochoice=True, exclude_unbiased=False)\n",
    "\n",
    "params['trials_mask_diagnostics'] = [trials_mask,\n",
    "                                     trials_mask_without_minrt,\n",
    "                                     trials_mask_without_maxrt,\n",
    "                                     trials_mask_withonly_nochoice]\n",
    "\n",
    "if params['target'] in ['wheel-vel', 'wheel-speed', 'l-whisker-me', 'r-whisker-me']:\n",
    "    # load target data\n",
    "    dlc_dict = load_behavior(params['target'], sess_loader)\n",
    "    # load imposter sessions\n",
    "    params['imposter_df'] = pd.read_parquet(imposter_file) if params['n_pseudo'] > 0 else None\n",
    "else:\n",
    "    dlc_dict = None\n",
    "    params['imposter_df'] = None\n",
    "\n",
    "if params['merged_probes']:\n",
    "    clusters_list = []\n",
    "    spikes_list = []\n",
    "    for pid, probe_name in zip(pids, probe_names):\n",
    "        tmp_spikes, tmp_clusters = load_good_units(one, pid, eid=eid, pname=probe_name)\n",
    "        tmp_clusters['pid'] = pid\n",
    "        spikes_list.append(tmp_spikes)\n",
    "        clusters_list.append(tmp_clusters)\n",
    "    spikes, clusters = merge_probes(spikes_list, clusters_list)\n",
    "else:\n",
    "    spikes, clusters = load_good_units(one, pid, eid=eid, pname=probe_name)\n",
    "\n",
    "neural_dict = {\n",
    "    'spk_times': spikes['times'],\n",
    "    'spk_clu': spikes['clusters'],\n",
    "    'clu_regions': clusters['acronym'],\n",
    "    'clu_qc': {k: np.asarray(v) for k, v in clusters.to_dict('list').items()},\n",
    "    'clu_df': clusters\n",
    "}\n",
    "\n",
    "metadata = {\n",
    "    'subject': subject,\n",
    "    'eid': eid,\n",
    "    'probe_name': probe_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d110b33a-0e94-4b7e-892d-a82fd9c79fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = params\n",
    "pseudo_id = -1\n",
    "pseudo_ids = -np.ones(1).astype('int64')\n",
    "kwargs['n_runs'] = 1\n",
    "kwargs['n_bins_lag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb8fb6e-8830-4b18-af80-17f6ca0b4f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on eid: 56956777-dca5-468c-87cb-78150432cc57\n",
      "\u001b[36m2023-11-06 21:49:24.573 INFO     [base_models.py:  289]   results found and loaded from /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/behavioral/NYU-11/model_actKernel_single_zeta/train_56956777.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(f'Working on eid: {metadata[\"eid\"]}')\n",
    "filenames = []  # this will contain paths to saved decoding results for this eid\n",
    "\n",
    "if kwargs['use_imposter_session'] and not kwargs['stitching_for_imposter_session']:\n",
    "    trials_df = trials_df[:int(kwargs['max_number_trials_when_no_stitching_for_imposter_session'])]\n",
    "\n",
    "if 0 in pseudo_ids:\n",
    "    raise ValueError(\n",
    "        'pseudo id can be -1 (actual session) or strictly greater than 0 (pseudo session)')\n",
    "\n",
    "if not np.all(np.sort(pseudo_ids) == pseudo_ids):\n",
    "    raise ValueError('pseudo_ids must be sorted')\n",
    "\n",
    "if kwargs['model'] == optimal_Bayesian and np.any(trials_df.probabilityLeft.values[:90] != 0.5):\n",
    "    raise ValueError(\n",
    "        'The optimal Bayesian model assumes 90 unbiased trials at the beginning of the '\n",
    "        'session, which is not the case here.')\n",
    "    \n",
    "# check if is trained\n",
    "eids_train = (\n",
    "    [metadata['eid']] if 'eids_train' not in metadata.keys() else metadata['eids_train'])\n",
    "if 'eids_train' not in metadata.keys():\n",
    "    metadata['eids_train'] = eids_train\n",
    "elif metadata['eids_train'] != eids_train:\n",
    "    raise ValueError(\n",
    "        'eids_train are not supported yet. If you do not understand this error, '\n",
    "        'just take out the eids_train key in the metadata to solve it')\n",
    "    \n",
    "if isinstance(kwargs['model'], str):\n",
    "    import pickle\n",
    "    from braindelphi.params import INTER_INDIVIDUAL_PATH\n",
    "    inter_individual = pickle.load(open(INTER_INDIVIDUAL_PATH.joinpath(kwargs['model']), 'rb'))\n",
    "    if metadata['eid'] not in inter_individual.keys():\n",
    "        logging.exception('no inter individual model found')\n",
    "        print(filenames)\n",
    "    inter_indiv_model_specifications = inter_individual[metadata['eid']]\n",
    "    print('winning interindividual model is %s' % inter_indiv_model_specifications['model_name'])\n",
    "    if inter_indiv_model_specifications['model_name'] not in kwargs['modeldispatcher'].values():\n",
    "        logging.exception('winning inter individual model is LeftKernel or RightKernel')\n",
    "        print(filenames)\n",
    "    kwargs['model'] = {v: k for k, v in kwargs['modeldispatcher'].items()}[inter_indiv_model_specifications['model_name']]\n",
    "    kwargs['model_parameters'] = inter_indiv_model_specifications['model_parameters']\n",
    "else:\n",
    "    kwargs['model_parameters'] = None\n",
    "    # train model if not trained already\n",
    "    if kwargs['model'] != optimal_Bayesian and kwargs['model'] is not None:\n",
    "        side, stim, act, _ = format_data_mut(trials_df)\n",
    "        stimuli, actions, stim_side = format_input_mut([stim], [act], [side])\n",
    "        behmodel = kwargs['model'](\n",
    "            kwargs['behfit_path'], np.array(metadata['eids_train']), metadata['subject'],\n",
    "            actions, stimuli, trials_df, stim_side, single_zeta=True)\n",
    "        istrained, _ = check_bhv_fit_exists(\n",
    "            metadata['subject'], kwargs['model'], metadata['eids_train'],\n",
    "            kwargs['behfit_path'], modeldispatcher=kwargs['modeldispatcher'], single_zeta=True)\n",
    "        if not istrained:\n",
    "            behmodel.load_or_train(remove_old=False)\n",
    "\n",
    "if kwargs['balanced_weight'] and kwargs['balanced_continuous_target']:\n",
    "    raise NotImplementedError(\"see tag `decoding_biasCWnull` for a previous implementation.\")\n",
    "else:\n",
    "    target_distribution = None\n",
    "    \n",
    "# get target values\n",
    "if kwargs['target'] in ['pLeft', 'signcont', 'strengthcont', 'choice', 'feedback']:\n",
    "    target_vals_list, target_vals_to_mask = compute_beh_target(\n",
    "        trials_df, metadata, return_raw=True, **kwargs)\n",
    "    target_mask = compute_target_mask(\n",
    "        target_vals_to_mask, kwargs['exclude_trials_within_values'])\n",
    "\n",
    "else:\n",
    "    if dlc_dict is None or dlc_dict['times'] is None or dlc_dict['values'] is None:\n",
    "        raise ValueError('dlc_dict does not contain any data')\n",
    "    _, target_vals_list, target_mask = get_target_data_per_trial_wrapper(\n",
    "        target_times=dlc_dict['times'],\n",
    "        target_vals=dlc_dict['values'],\n",
    "        trials_df=trials_df,\n",
    "        align_event=kwargs['align_time'],\n",
    "        align_interval=kwargs['time_window'],\n",
    "        binsize=kwargs['binsize'])\n",
    "    \n",
    "mask = trials_mask & target_mask\n",
    "\n",
    "if sum(mask) <= kwargs['min_behav_trials']:\n",
    "    msg = 'session contains %i trials, below the threshold of %i' % (\n",
    "        sum(mask), kwargs['min_behav_trials'])\n",
    "    logging.exception(msg)\n",
    "    print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a700b8-af4e-434e-95dc-ccd2a7175836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select brain regions from beryl atlas to loop over\n",
    "brainreg = BrainRegions()\n",
    "beryl_reg = brainreg.acronym2acronym(neural_dict['clu_regions'], mapping='Beryl')\n",
    "regions = (\n",
    "    [[k] for k in np.unique(beryl_reg)] if kwargs['single_region'] else [np.unique(beryl_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebfa171e-b84d-4374-aa75-5e93b0880caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 56956777-dca5-468c-87cb-78150432cc57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "region_results = {}\n",
    "for region in tqdm(regions, desc='Region: ', leave=False):\n",
    "\n",
    "    # pull spikes from this region out of the neural data\n",
    "    reg_clu_ids = select_ephys_regions(neural_dict, beryl_reg, region, **kwargs)\n",
    "\n",
    "    # skip region if there are not enough units\n",
    "    n_units = len(reg_clu_ids)\n",
    "    if n_units < kwargs['min_units']:\n",
    "        continue\n",
    "\n",
    "    # bin spikes from this region for each trial\n",
    "    msub_binned, cl_inds_used = preprocess_ephys(reg_clu_ids, neural_dict, trials_df, **kwargs)\n",
    "    cl_uuids_used = list(neural_dict['clu_df'].iloc[cl_inds_used]['uuids'])\n",
    "\n",
    "    # make design matrix\n",
    "    bins_per_trial = msub_binned[0].shape[0]\n",
    "    Xs = (\n",
    "        msub_binned if bins_per_trial == 1\n",
    "        else [build_predictor_matrix(s, kwargs['n_bins_lag']) for s in msub_binned]\n",
    "    )\n",
    "    \n",
    "    control_mask = mask\n",
    "    save_predictions = kwargs['save_predictions']\n",
    "\n",
    "    # original session\n",
    "    ys_wmask = [target_vals_list[m] for m in np.squeeze(np.where(mask))]\n",
    "    Xs_wmask = [Xs[m] for m in np.squeeze(np.where(mask))]\n",
    "    \n",
    "    fit_results = []\n",
    "    for i_run in range(kwargs['n_runs']):\n",
    "\n",
    "        rng_seed = i_run\n",
    "\n",
    "        fit_result = decode_cv(\n",
    "            ys=ys_wmask,\n",
    "            Xs=Xs_wmask,\n",
    "            estimator=kwargs['estimator'],\n",
    "            use_openturns=kwargs['use_openturns'],\n",
    "            target_distribution=target_distribution,\n",
    "            balanced_continuous_target=kwargs['balanced_continuous_target'],\n",
    "            estimator_kwargs=kwargs['estimator_kwargs'],\n",
    "            hyperparam_grid=kwargs['hyperparam_grid'],\n",
    "            save_binned=kwargs['save_binned'] if pseudo_id == -1 else False,\n",
    "            save_predictions=save_predictions,\n",
    "            shuffle=kwargs['shuffle'],\n",
    "            balanced_weight=kwargs['balanced_weight'],\n",
    "            rng_seed=rng_seed,\n",
    "        )\n",
    "        fit_result['mask'] = mask\n",
    "        fit_result['mask_trials_and_targets'] = [trials_mask, target_mask]\n",
    "        fit_result['mask_diagnostics'] = kwargs['trials_mask_diagnostics']\n",
    "        fit_result['df'] = trials_df if pseudo_id == -1 else controlsess_df\n",
    "        fit_result['pseudo_id'] = pseudo_id\n",
    "        fit_result['run_id'] = i_run\n",
    "        fit_result['cluster_uuids'] = cl_uuids_used\n",
    "        fit_results.append(fit_result)\n",
    "        \n",
    "    region_results.update({region[0]: fit_results[0]['acc_test_full']})\n",
    "        \n",
    "print(f'Finished eid: {metadata[\"eid\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1353a062-41e5-4561-85d9-2f2a60136bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMA': 0.5836734693877551,\n",
       " 'CA1': 0.4489795918367347,\n",
       " 'CA3': 0.5673469387755102,\n",
       " 'CEA': 0.5755102040816327,\n",
       " 'COAp': 0.5306122448979592,\n",
       " 'GPe': 0.6612244897959184,\n",
       " 'IA': 0.5877551020408164,\n",
       " 'LGd': 0.7346938775510204,\n",
       " 'PA': 0.5673469387755102,\n",
       " 'SSp-bfd': 0.5959183673469388,\n",
       " 'SSp-tr': 0.636734693877551,\n",
       " 'VISa': 0.5795918367346938,\n",
       " 'VPM': 0.563265306122449,\n",
       " 'root': 0.6571428571428571}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no time binning\n",
    "region_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a496e3e-c31e-4848-baa8-63bd7f840c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMA': 0.5673469387755102,\n",
       " 'CA1': 0.5591836734693878,\n",
       " 'CA3': 0.5469387755102041,\n",
       " 'CEA': 0.5224489795918368,\n",
       " 'COAp': 0.5142857142857142,\n",
       " 'GPe': 0.6204081632653061,\n",
       " 'IA': 0.5551020408163265,\n",
       " 'LGd': 0.6693877551020408,\n",
       " 'PA': 0.5755102040816327,\n",
       " 'SSp-bfd': 0.6285714285714286,\n",
       " 'SSp-tr': 0.5959183673469388,\n",
       " 'VISa': 0.5673469387755102,\n",
       " 'VPM': 0.5877551020408164,\n",
       " 'root': 0.5836734693877551}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.02 time bin\n",
    "region_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f09cf-d86d-4530-adeb-31248f4d4c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23c05771-c8e1-4e9b-8083-c503b07896ff",
   "metadata": {},
   "source": [
    "### reduced rank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c9236c7-ebca-4259-bb6a-a3da3e3145e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xs = np.array(Xs_wmask).transpose(0,-1,1)\n",
    "ys = np.array(ys_wmask).astype(float).reshape(-1,1)\n",
    "_, n_units, n_t_bins = Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d4c457c-3e8d-4c08-b1f9-a1bee71f33fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cbceca8d-3df9-444e-8697-0157578995a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReducedRank(nn.Module):\n",
    "\n",
    "    def __init__(self, n_units, n_t_bins, rank):\n",
    "        super().__init__()\n",
    "        self.U = nn.Parameter(torch.randn(n_units, rank))\n",
    "        self.V = nn.Parameter(torch.randn(rank, n_t_bins))\n",
    "        self.b = nn.Parameter(torch.randn((1,)))\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        Beta = torch.einsum(\"cr,rt->ct\", self.U, self.V)\n",
    "        out = torch.einsum(\"ct,kct->k\", Beta, x)\n",
    "        out += self.b.tile((batch_size,))\n",
    "        out = out.reshape(-1,1)\n",
    "        return out, self.U, self.V\n",
    "\n",
    "class LightningReducedRank(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone    \n",
    "\n",
    "    def cross_entropy_loss(self, preds, labels):\n",
    "        return F.binary_cross_entropy_with_logits(preds, labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out, U, V = self.backbone(x)\n",
    "        loss = self.cross_entropy_loss(out, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out, U, V = self.backbone(x)\n",
    "        loss = self.cross_entropy_loss(out, y)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e79e7e37-1d90-45aa-bbb0-8a9cc1f848b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralDataset(Dataset):\n",
    "    def __init__(self, neural_data, behavioral_data):\n",
    "        self.neural_data = neural_data\n",
    "        self.behavioral_data = behavioral_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.neural_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.neural_data[idx], self.behavioral_data[idx]\n",
    "        X = torch.from_numpy(X)\n",
    "        y = torch.from_numpy(y)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "915006ca-ea7e-4190-936c-e3f9942051f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "backbone = ReducedRank(n_units, n_t_bins, rank=2)\n",
    "model = LightningReducedRank(backbone)\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\", precision=\"16-mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0bd44f93-3db5-4c29-a37f-751e986ca3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = NeuralDataset(Xs, ys)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fffbba66-5dc8-43bb-85bf-3a45d502a69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, num_workers=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, num_workers=1)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, num_workers=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "719c9193-31a4-4a7a-809b-7de5e3bcf94e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | backbone | ReducedRank | 93    \n",
      "-----------------------------------------\n",
      "93        Trainable params\n",
      "0         Non-trainable params\n",
      "93        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251:   0%|                               | 0/25 [00:00<?, ?it/s, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fc3c094ab90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261:  68%|██████████████▎      | 17/25 [00:00<00:00, 102.56it/s, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ee726-18b2-4826-852d-3c185bf2de40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c9285-ee63-4c84-bb92-52335a3246ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
