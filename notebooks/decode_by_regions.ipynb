{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34812d8d-a1c4-4cab-a1c1-96b04fa8992b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizi/anaconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/__init__.py:202: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SessionLoader\n",
    "from iblatlas.regions import BrainRegions\n",
    "\n",
    "from sklearn import linear_model as sklm\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from behavior_models.utils import format_data as format_data_mut\n",
    "from behavior_models.utils import format_input as format_input_mut\n",
    "\n",
    "from brainwidemap.bwm_loading import load_good_units, load_all_units, load_trials_and_mask, merge_probes\n",
    "from brainwidemap.decoding.functions.process_targets import load_behavior\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import params\n",
    "from brainwidemap.decoding.settings_for_BWM_figure.settings_choice import RESULTS_DIR\n",
    "\n",
    "from brainwidemap.decoding.functions.balancedweightings import balanced_weighting\n",
    "from brainwidemap.decoding.functions.process_inputs import (\n",
    "    build_predictor_matrix,\n",
    "    select_ephys_regions,\n",
    "    preprocess_ephys\n",
    ")\n",
    "from brainwidemap.decoding.functions.process_targets import (\n",
    "    compute_beh_target,\n",
    "    compute_target_mask,\n",
    "    transform_data_for_decoding,\n",
    "    logisticreg_criteria,\n",
    "    get_target_data_per_trial_wrapper,\n",
    "    check_bhv_fit_exists,\n",
    "    optimal_Bayesian\n",
    ")\n",
    "from brainwidemap.decoding.functions.utils import save_region_results, get_save_path\n",
    "from brainwidemap.decoding.functions.nulldistributions import generate_null_distribution_session\n",
    "from brainwidemap.decoding.functions.decoding import decode_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4976e-a2b4-4ab6-8576-f220e9bd572f",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06554af5-db49-4411-96d4-08bedf04551e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['behfit_path'] = RESULTS_DIR.joinpath('decoding', 'results', 'behavioral')\n",
    "params['behfit_path'].mkdir(parents=True, exist_ok=True)\n",
    "params['neuralfit_path'] = RESULTS_DIR.joinpath('decoding', 'results', 'neural')\n",
    "params['neuralfit_path'].mkdir(parents=True, exist_ok=True)\n",
    "params['add_to_saving_path'] = (f\"_binsize={1000 * params['binsize']}_lags={params['n_bins_lag']}_\"\n",
    "                                f\"mergedProbes_{params['merged_probes']}\")\n",
    "imposter_file = RESULTS_DIR.joinpath('decoding', f\"imposterSessions_{params['target']}.pqt\")\n",
    "bwm_session_file = RESULTS_DIR.joinpath('decoding', 'bwm_cache_sessions.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1316757c-d3ca-48bc-9bf4-67c06d296821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimOn_times\n"
     ]
    }
   ],
   "source": [
    "params[\"align_time\"] = \"stimOn_times\"\n",
    "# params[\"align_time\"] = \"firstMovement_times\"\n",
    "print(params[\"align_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910af896-fb9c-45e8-9ac1-7856e7c304c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.5, 1.0)\n"
     ]
    }
   ],
   "source": [
    "params[\"time_window\"] = (-0.5, 1.)\n",
    "# params[\"time_window\"] = (-.1, .0)\n",
    "print(params[\"time_window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6993fba-3688-4180-88e8-55779486553c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "params[\"binsize\"] = 0.05\n",
    "# params[\"binsize\"] = 0.1\n",
    "print(params[\"binsize\"])\n",
    "params['n_pseudo'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f477db7-e72d-453a-b05e-488ebbcaecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one = ONE(base_url=\"https://openalyx.internationalbrainlab.org\", mode='remote')\n",
    "bwm_df = pd.read_parquet(bwm_session_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28730ab-0c65-425a-83bb-47bb1b6c558f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi = \"PO\"\n",
    "pids_per_region = one.search_insertions(atlas_acronym=[roi], query_type='remote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c6eba6-b886-4db5-907f-e3dd5c93d4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>eid</th>\n",
       "      <th>probe_name</th>\n",
       "      <th>session_number</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>e8129a86-b5a9-4d2e-9e9c-09689c9bf0b3</td>\n",
       "      <td>a4000c2f-fa75-4b3e-8f06-a7cf599b87ad</td>\n",
       "      <td>probe00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>KS023</td>\n",
       "      <td>cortexlab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>36362f75-96d8-4ed4-a728-5e72284d0995</td>\n",
       "      <td>d0ea3148-948d-4817-94f8-dcaf2342bbbe</td>\n",
       "      <td>probe00</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>ZFM-01936</td>\n",
       "      <td>mainenlab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>bebe7c8f-0f34-4c3a-8fbb-d2a5119d2961</td>\n",
       "      <td>f25642c6-27a5-4a97-9ea0-06652db79fbd</td>\n",
       "      <td>probe00</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>DY_014</td>\n",
       "      <td>danlab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pid  \\\n",
       "150  e8129a86-b5a9-4d2e-9e9c-09689c9bf0b3   \n",
       "338  36362f75-96d8-4ed4-a728-5e72284d0995   \n",
       "238  bebe7c8f-0f34-4c3a-8fbb-d2a5119d2961   \n",
       "\n",
       "                                      eid probe_name  session_number  \\\n",
       "150  a4000c2f-fa75-4b3e-8f06-a7cf599b87ad    probe00               1   \n",
       "338  d0ea3148-948d-4817-94f8-dcaf2342bbbe    probe00               1   \n",
       "238  f25642c6-27a5-4a97-9ea0-06652db79fbd    probe00               1   \n",
       "\n",
       "           date    subject        lab  \n",
       "150  2019-12-06      KS023  cortexlab  \n",
       "338  2021-01-19  ZFM-01936  mainenlab  \n",
       "238  2020-07-13     DY_014     danlab  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwm_df = bwm_df.loc[bwm_df.pid.isin(pids_per_region)]\n",
    "bwm_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a4cd4d-d936-4607-8620-5eb3cbd5930d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yizi/decode-brain-wide-map/results/PO/stimOn_times_-0.5_1.0_0.05_all_units.npy\n"
     ]
    }
   ],
   "source": [
    "unit_type = \"all_units\"\n",
    "dir_path = Path(\"/home/yizi/decode-brain-wide-map/results\")\n",
    "res_path = dir_path/roi/f'{params[\"align_time\"]}_{params[\"time_window\"][0]}_{params[\"time_window\"][1]}_{params[\"binsize\"]}_{unit_type}.npy'\n",
    "print(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb9b27e-ac16-4f17-a5da-4e12a084ee9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bwm_df = bwm_df.loc[bwm_df.eid != 'a4000c2f-fa75-4b3e-8f06-a7cf599b87ad']\n",
    "bwm_df = bwm_df.loc[bwm_df.eid != 'aad23144-0e52-4eac-80c5-c4ee2decb198']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b81f3071-3c09-4590-a5e2-b51bcd24a8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_by_eids, filenames_by_eids = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baece939-7e7a-49c5-8430-8dc7d335d44b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running merged probes for session eid: 6ed57216-498d-48a6-b48b-a243a34710ea\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 6ed57216-498d-48a6-b48b-a243a34710ea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n",
      "results for region PO, pseudo_id -1 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_-1__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 1 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_1__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 2 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_2__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 3 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_3__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 4 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_4__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 5 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_5__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 6 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_6__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "results for region PO, pseudo_id 7 already exist at /mnt/3TB/yizi/decode-paper-brain-wide-map/decoding/results/neural/ephys/NYU-39/6ed57216-498d-48a6-b48b-a243a34710ea/probe00/01-04-2023_PO_target_choice_timeWindow_-0_5_1_0_pseudo_id_7__binsize=50.0_lags=None_mergedProbes_True.pkl\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 6ed57216-498d-48a6-b48b-a243a34710ea\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254]}\n",
      "Running merged probes for session eid: 51e53aff-1d5d-4182-a684-aba783d50ae5\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 51e53aff-1d5d-4182-a684-aba783d50ae5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 51e53aff-1d5d-4182-a684-aba783d50ae5\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139]}\n",
      "Running merged probes for session eid: 5386aba9-9b97-4557-abcd-abc2da66b863\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 5386aba9-9b97-4557-abcd-abc2da66b863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n",
      "sampled pseudo sessions 3 times to ensure valid target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 5386aba9-9b97-4557-abcd-abc2da66b863\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987]}\n",
      "Running merged probes for session eid: 4b00df29-3769-43be-bb40-128b1cba6d35\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 4b00df29-3769-43be-bb40-128b1cba6d35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 4b00df29-3769-43be-bb40-128b1cba6d35\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987], '4b00df29-3769-43be-bb40-128b1cba6d35': [0.6945678620543743, 0.4926268027872306, 0.20194105926714367]}\n",
      "Running merged probes for session eid: f312aaec-3b6f-44b3-86b4-3a0c119c0438\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: f312aaec-3b6f-44b3-86b4-3a0c119c0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: f312aaec-3b6f-44b3-86b4-3a0c119c0438\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987], '4b00df29-3769-43be-bb40-128b1cba6d35': [0.6945678620543743, 0.4926268027872306, 0.20194105926714367], 'f312aaec-3b6f-44b3-86b4-3a0c119c0438': [0.5960544389820706, 0.5010530510018215, 0.09500138798024904]}\n",
      "Running merged probes for session eid: 19e66dc9-bf9f-430b-9d6a-acfa85de6fb7\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 19e66dc9-bf9f-430b-9d6a-acfa85de6fb7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 19e66dc9-bf9f-430b-9d6a-acfa85de6fb7\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987], '4b00df29-3769-43be-bb40-128b1cba6d35': [0.6945678620543743, 0.4926268027872306, 0.20194105926714367], 'f312aaec-3b6f-44b3-86b4-3a0c119c0438': [0.5960544389820706, 0.5010530510018215, 0.09500138798024904], '19e66dc9-bf9f-430b-9d6a-acfa85de6fb7': [0.7230833682446586, 0.4717801972827098, 0.25130317096194876]}\n",
      "Running merged probes for session eid: 824cf03d-4012-4ab1-b499-c83a92c5589e\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 824cf03d-4012-4ab1-b499-c83a92c5589e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 824cf03d-4012-4ab1-b499-c83a92c5589e\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987], '4b00df29-3769-43be-bb40-128b1cba6d35': [0.6945678620543743, 0.4926268027872306, 0.20194105926714367], 'f312aaec-3b6f-44b3-86b4-3a0c119c0438': [0.5960544389820706, 0.5010530510018215, 0.09500138798024904], '19e66dc9-bf9f-430b-9d6a-acfa85de6fb7': [0.7230833682446586, 0.4717801972827098, 0.25130317096194876], '824cf03d-4012-4ab1-b499-c83a92c5589e': [0.7856895356895357, 0.5103656727488504, 0.27532386294068534]}\n",
      "Running merged probes for session eid: 1f095590-6669-46c9-986b-ccaf0620c5e9\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 1f095590-6669-46c9-986b-ccaf0620c5e9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 1f095590-6669-46c9-986b-ccaf0620c5e9\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987], '4b00df29-3769-43be-bb40-128b1cba6d35': [0.6945678620543743, 0.4926268027872306, 0.20194105926714367], 'f312aaec-3b6f-44b3-86b4-3a0c119c0438': [0.5960544389820706, 0.5010530510018215, 0.09500138798024904], '19e66dc9-bf9f-430b-9d6a-acfa85de6fb7': [0.7230833682446586, 0.4717801972827098, 0.25130317096194876], '824cf03d-4012-4ab1-b499-c83a92c5589e': [0.7856895356895357, 0.5103656727488504, 0.27532386294068534], '1f095590-6669-46c9-986b-ccaf0620c5e9': [0.8625076522803795, 0.49655163859187773, 0.3659560136885018]}\n",
      "Running merged probes for session eid: 3f859b5c-e73a-4044-b49e-34bb81e96715\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 3f859b5c-e73a-4044-b49e-34bb81e96715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n",
      "sampled pseudo sessions 2 times to ensure valid target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished eid: 3f859b5c-e73a-4044-b49e-34bb81e96715\n",
      "{'6ed57216-498d-48a6-b48b-a243a34710ea': [0.8491459693142325, 0.48757264882000706, 0.3615733204942254], '51e53aff-1d5d-4182-a684-aba783d50ae5': [0.8968897903989181, 0.5446247464503042, 0.3522650439486139], '5386aba9-9b97-4557-abcd-abc2da66b863': [0.6309535280977618, 0.513454218876962, 0.11749930922079987], '4b00df29-3769-43be-bb40-128b1cba6d35': [0.6945678620543743, 0.4926268027872306, 0.20194105926714367], 'f312aaec-3b6f-44b3-86b4-3a0c119c0438': [0.5960544389820706, 0.5010530510018215, 0.09500138798024904], '19e66dc9-bf9f-430b-9d6a-acfa85de6fb7': [0.7230833682446586, 0.4717801972827098, 0.25130317096194876], '824cf03d-4012-4ab1-b499-c83a92c5589e': [0.7856895356895357, 0.5103656727488504, 0.27532386294068534], '1f095590-6669-46c9-986b-ccaf0620c5e9': [0.8625076522803795, 0.49655163859187773, 0.3659560136885018], '3f859b5c-e73a-4044-b49e-34bb81e96715': [0.6288400325708787, 0.5557152456323727, 0.07312478693850599]}\n",
      "Running merged probes for session eid: 8928f98a-b411-497e-aa4b-aa752434686d\n",
      "error loading choice data\n",
      "\n",
      "Working on eid: 8928f98a-b411-497e-aa4b-aa752434686d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region:   0%|                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, bwm_df.shape[0]):\n",
    "\n",
    "    job_repeat = 0 \n",
    "    pseudo_ids = np.arange(job_repeat * params['n_pseudo_per_job'], (job_repeat + 1) * params['n_pseudo_per_job']) + 1\n",
    "    if 1 in pseudo_ids:\n",
    "        pseudo_ids = np.concatenate((-np.ones(1), pseudo_ids)).astype('int64')\n",
    "    if pseudo_ids[0] > params['n_pseudo']:\n",
    "        print(f\"ended job because this job_repeat ({job_repeat}) does not include any pseudo sessions < {params['n_pseudo']}\")\n",
    "        exit()\n",
    "    if pseudo_ids[-1] > params['n_pseudo']:\n",
    "        print(f\"truncated job because this job_repeat ({job_repeat}) includes more than {params['n_pseudo']} pseudo sessions\")\n",
    "        pseudo_ids = pseudo_ids[pseudo_ids <= params['n_pseudo']]\n",
    "\n",
    "    if params['merged_probes']:\n",
    "        eid = bwm_df['eid'].unique()[idx]\n",
    "        tmp_df = bwm_df.set_index(['eid', 'subject']).xs(eid, level='eid')\n",
    "        subject = tmp_df.index[0]\n",
    "        pids = tmp_df['pid'].to_list()  # Select all probes of this session\n",
    "        probe_names = tmp_df['probe_name'].to_list()\n",
    "        print(f\"Running merged probes for session eid: {eid}\")\n",
    "    else:\n",
    "        eid = bwm_df.iloc[idx]['eid']\n",
    "        subject = bwm_df.iloc[idx]['subject']\n",
    "        pid = bwm_df.iloc[idx]['pid']\n",
    "        probe_name = bwm_df.iloc[idx]['probe_name']\n",
    "        print(f\"Running probe pid: {pid}\")\n",
    "\n",
    "    sess_loader = SessionLoader(one, eid)\n",
    "    sess_loader.load_trials()\n",
    "\n",
    "    trials_df, trials_mask = load_trials_and_mask(\n",
    "        one=one, eid=eid, sess_loader=sess_loader, min_rt=params['min_rt'], max_rt=params['max_rt'],\n",
    "        min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "        exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "    _, trials_mask_without_minrt = load_trials_and_mask(\n",
    "        one=one, eid=eid, sess_loader=sess_loader, min_rt=None, max_rt=params['max_rt'],\n",
    "        min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "        exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "    _, trials_mask_without_maxrt = load_trials_and_mask(\n",
    "        one=one, eid=eid, sess_loader=sess_loader, min_rt=params['min_rt'], max_rt=None,\n",
    "        min_trial_len=params['min_len'], max_trial_len=params['max_len'],\n",
    "        exclude_nochoice=True, exclude_unbiased=params['exclude_unbiased_trials'])\n",
    "    _, trials_mask_withonly_nochoice = load_trials_and_mask(\n",
    "        one=one, eid=eid, sess_loader=sess_loader, min_rt=None, max_rt=None,\n",
    "        min_trial_len=None, max_trial_len=None,\n",
    "        exclude_nochoice=True, exclude_unbiased=False)\n",
    "\n",
    "    params['trials_mask_diagnostics'] = [trials_mask,\n",
    "                                         trials_mask_without_minrt,\n",
    "                                         trials_mask_without_maxrt,\n",
    "                                         trials_mask_withonly_nochoice]\n",
    "\n",
    "    # if params['target'] in ['wheel-vel', 'wheel-speed', 'l-whisker-me', 'r-whisker-me']:\n",
    "    if params['target'] in ['choice', 'wheel-vel', 'wheel-speed', 'l-whisker-me', 'r-whisker-me']:\n",
    "        # load target data\n",
    "        dlc_dict = load_behavior(params['target'], sess_loader)\n",
    "        # load imposter sessions\n",
    "        params['imposter_df'] = pd.read_parquet(imposter_file) if params['n_pseudo'] > 0 else None\n",
    "    else:\n",
    "        dlc_dict = None\n",
    "        params['imposter_df'] = None\n",
    "\n",
    "    if params['merged_probes']:\n",
    "        clusters_list = []\n",
    "        spikes_list = []\n",
    "        for pid, probe_name in zip(pids, probe_names):\n",
    "            # tmp_spikes, tmp_clusters = load_good_units(one, pid, eid=eid, pname=probe_name)\n",
    "            tmp_spikes, tmp_clusters = load_all_units(one, pid, eid=eid, pname=probe_name)\n",
    "            tmp_clusters['pid'] = pid\n",
    "            spikes_list.append(tmp_spikes)\n",
    "            clusters_list.append(tmp_clusters)\n",
    "        spikes, clusters = merge_probes(spikes_list, clusters_list)\n",
    "    else:\n",
    "        # spikes, clusters = load_good_units(one, pid, eid=eid, pname=probe_name)\n",
    "        spikes, clusters = load_all_units(one, pid, eid=eid, pname=probe_name)\n",
    "\n",
    "    neural_dict = {\n",
    "        'spk_times': spikes['times'],\n",
    "        'spk_clu': spikes['clusters'],\n",
    "        'clu_regions': clusters['acronym'],\n",
    "        'clu_qc': {k: np.asarray(v) for k, v in clusters.to_dict('list').items()},\n",
    "        'clu_df': clusters\n",
    "    }\n",
    "\n",
    "    metadata = {\n",
    "        'subject': subject,\n",
    "        'eid': eid,\n",
    "        'probe_name': probe_name\n",
    "    }\n",
    "    \n",
    "    kwargs = params\n",
    "    kwargs['n_runs'] = 1\n",
    "    kwargs['n_bins_lag'] = 0\n",
    "    \n",
    "    # select brain regions from beryl atlas to loop over\n",
    "    brainreg = BrainRegions()\n",
    "    beryl_reg = brainreg.acronym2acronym(neural_dict['clu_regions'], mapping='Beryl')\n",
    "    regions = (\n",
    "        [[k] for k in np.unique(beryl_reg)] if kwargs['single_region'] else [np.unique(beryl_reg)])\n",
    "    \n",
    "    if [roi] not in regions:\n",
    "        print(f\"{roi} not found. Skip to next eid.\")\n",
    "        continue\n",
    "    \n",
    "    print(f'Working on eid: {metadata[\"eid\"]}')\n",
    "    filenames = []  # this will contain paths to saved decoding results for this eid\n",
    "\n",
    "    kwargs['use_imposter_session'] = True\n",
    "    if kwargs['use_imposter_session'] and not kwargs['stitching_for_imposter_session']:\n",
    "        trials_df = trials_df[:int(kwargs['max_number_trials_when_no_stitching_for_imposter_session'])]\n",
    "\n",
    "    if 0 in pseudo_ids:\n",
    "        raise ValueError(\n",
    "            'pseudo id can be -1 (actual session) or strictly greater than 0 (pseudo session)')\n",
    "\n",
    "    if not np.all(np.sort(pseudo_ids) == pseudo_ids):\n",
    "        raise ValueError('pseudo_ids must be sorted')\n",
    "\n",
    "    if kwargs['model'] == optimal_Bayesian and np.any(trials_df.probabilityLeft.values[:90] != 0.5):\n",
    "        raise ValueError(\n",
    "            'The optimal Bayesian model assumes 90 unbiased trials at the beginning of the '\n",
    "            'session, which is not the case here.')\n",
    "\n",
    "    # check if is trained\n",
    "    eids_train = (\n",
    "        [metadata['eid']] if 'eids_train' not in metadata.keys() else metadata['eids_train'])\n",
    "    if 'eids_train' not in metadata.keys():\n",
    "        metadata['eids_train'] = eids_train\n",
    "    elif metadata['eids_train'] != eids_train:\n",
    "        raise ValueError(\n",
    "            'eids_train are not supported yet. If you do not understand this error, '\n",
    "            'just take out the eids_train key in the metadata to solve it')\n",
    "\n",
    "    if isinstance(kwargs['model'], str):\n",
    "        import pickle\n",
    "        from braindelphi.params import INTER_INDIVIDUAL_PATH\n",
    "        inter_individual = pickle.load(open(INTER_INDIVIDUAL_PATH.joinpath(kwargs['model']), 'rb'))\n",
    "        if metadata['eid'] not in inter_individual.keys():\n",
    "            logging.exception('no inter individual model found')\n",
    "            print(filenames)\n",
    "        inter_indiv_model_specifications = inter_individual[metadata['eid']]\n",
    "        print('winning interindividual model is %s' % inter_indiv_model_specifications['model_name'])\n",
    "        if inter_indiv_model_specifications['model_name'] not in kwargs['modeldispatcher'].values():\n",
    "            logging.exception('winning inter individual model is LeftKernel or RightKernel')\n",
    "            print(filenames)\n",
    "        kwargs['model'] = {v: k for k, v in kwargs['modeldispatcher'].items()}[inter_indiv_model_specifications['model_name']]\n",
    "        kwargs['model_parameters'] = inter_indiv_model_specifications['model_parameters']\n",
    "    else:\n",
    "        kwargs['model_parameters'] = None\n",
    "        # train model if not trained already\n",
    "        if kwargs['model'] != optimal_Bayesian and kwargs['model'] is not None:\n",
    "            side, stim, act, _ = format_data_mut(trials_df)\n",
    "            stimuli, actions, stim_side = format_input_mut([stim], [act], [side])\n",
    "            behmodel = kwargs['model'](\n",
    "                kwargs['behfit_path'], np.array(metadata['eids_train']), metadata['subject'],\n",
    "                actions, stimuli, trials_df, stim_side, single_zeta=True)\n",
    "            istrained, _ = check_bhv_fit_exists(\n",
    "                metadata['subject'], kwargs['model'], metadata['eids_train'],\n",
    "                kwargs['behfit_path'], modeldispatcher=kwargs['modeldispatcher'], single_zeta=True)\n",
    "            if not istrained:\n",
    "                behmodel.load_or_train(remove_old=False)\n",
    "\n",
    "    if kwargs['balanced_weight'] and kwargs['balanced_continuous_target']:\n",
    "        raise NotImplementedError(\"see tag `decoding_biasCWnull` for a previous implementation.\")\n",
    "    else:\n",
    "        target_distribution = None\n",
    "\n",
    "    # get target values\n",
    "    if kwargs['target'] in ['pLeft', 'signcont', 'strengthcont', 'choice', 'feedback']:\n",
    "        target_vals_list, target_vals_to_mask = compute_beh_target(\n",
    "            trials_df, metadata, return_raw=True, **kwargs)\n",
    "        target_mask = compute_target_mask(\n",
    "            target_vals_to_mask, kwargs['exclude_trials_within_values'])\n",
    "\n",
    "    else:\n",
    "        if dlc_dict is None or dlc_dict['times'] is None or dlc_dict['values'] is None:\n",
    "            raise ValueError('dlc_dict does not contain any data')\n",
    "        _, target_vals_list, target_mask = get_target_data_per_trial_wrapper(\n",
    "            target_times=dlc_dict['times'],\n",
    "            target_vals=dlc_dict['values'],\n",
    "            trials_df=trials_df,\n",
    "            align_event=kwargs['align_time'],\n",
    "            align_interval=kwargs['time_window'],\n",
    "            binsize=kwargs['binsize'])\n",
    "\n",
    "    mask = trials_mask & target_mask\n",
    "\n",
    "    if sum(mask) <= kwargs['min_behav_trials']:\n",
    "        msg = 'session contains %i trials, below the threshold of %i' % (\n",
    "            sum(mask), kwargs['min_behav_trials'])\n",
    "        logging.exception(msg)\n",
    "        print(filenames)\n",
    "        \n",
    "    roi_idx = np.argwhere(np.array([region[0].find(roi) for region in regions]) == 0).astype(int)\n",
    "    regions = regions[roi_idx[0][0]]\n",
    "    for region in tqdm(regions, desc='Region: ', leave=False):\n",
    "        \n",
    "        print(regions[0])\n",
    "        # pull spikes from this region out of the neural data\n",
    "        reg_clu_ids = select_ephys_regions(neural_dict, beryl_reg, region, **kwargs)\n",
    "\n",
    "        # skip region if there are not enough units\n",
    "        n_units = len(reg_clu_ids)\n",
    "        if n_units < kwargs['min_units']:\n",
    "            continue\n",
    "\n",
    "        # bin spikes from this region for each trial\n",
    "        msub_binned, cl_inds_used = preprocess_ephys(reg_clu_ids, neural_dict, trials_df, **kwargs)\n",
    "        cl_uuids_used = list(neural_dict['clu_df'].iloc[cl_inds_used]['uuids'])\n",
    "\n",
    "        # make design matrix\n",
    "        bins_per_trial = msub_binned[0].shape[0]\n",
    "        Xs = (\n",
    "            msub_binned if bins_per_trial == 1\n",
    "            else [build_predictor_matrix(s, kwargs['n_bins_lag']) for s in msub_binned]\n",
    "        )\n",
    "\n",
    "        for pseudo_id in pseudo_ids:\n",
    "            fit_results = []\n",
    "\n",
    "            # save out decoding results\n",
    "            save_path = get_save_path(\n",
    "                pseudo_id, metadata['subject'], metadata['eid'], 'ephys',\n",
    "                probe=metadata['probe_name'],\n",
    "                region=str(np.squeeze(region)) if kwargs['single_region'] else 'allRegions',\n",
    "                output_path=kwargs['neuralfit_path'],\n",
    "                time_window=kwargs['time_window'],\n",
    "                date=kwargs['date'],\n",
    "                target=kwargs['target'],\n",
    "                add_to_saving_path=kwargs['add_to_saving_path']\n",
    "            )\n",
    "            if os.path.exists(save_path):\n",
    "                print(\n",
    "                    f'results for region {region}, pseudo_id {pseudo_id} already exist at '\n",
    "                    f'{save_path}')\n",
    "                filenames.append(save_path)\n",
    "                continue\n",
    "\n",
    "            # get data matrix and target, resampling when there are <3 incorrect trials\n",
    "\n",
    "            # create pseudo/imposter session when necessary, corresponding mask, and data matrix\n",
    "            if pseudo_id > 0:\n",
    "                ys_wmask = None\n",
    "                Xs_wmask = None\n",
    "                sample_pseudo_count = 0\n",
    "                while (kwargs['estimator']==sklm.LogisticRegression and (not logisticreg_criteria(ys_wmask))) or (ys_wmask is None):\n",
    "                    assert sample_pseudo_count < 100 # must be a reasonable number of sample or else something is wrong\n",
    "                    sample_pseudo_count += 1\n",
    "                    if bins_per_trial == 1:\n",
    "                        controlsess_df = generate_null_distribution_session(\n",
    "                            trials_df, metadata, **kwargs)\n",
    "                        controltarget_vals_list, controltarget_vals_to_mask = compute_beh_target(\n",
    "                            controlsess_df, metadata, return_raw=True, **kwargs)\n",
    "                        controltarget_mask = compute_target_mask(\n",
    "                            controltarget_vals_to_mask, kwargs['exclude_trials_within_values'])\n",
    "                        control_mask = trials_mask & controltarget_mask\n",
    "                    else:\n",
    "                        imposter_df = kwargs['imposter_df'].copy()\n",
    "                        # remove current eid from imposter sessions\n",
    "                        df_clean = imposter_df[imposter_df.eid != metadata['eid']].reset_index()\n",
    "                        # randomly select imposter trial to start sequence\n",
    "                        n_trials = trials_df.index.size\n",
    "                        total_imposter_trials = df_clean.shape[0]\n",
    "                        idx_beg = np.random.choice(total_imposter_trials - n_trials)\n",
    "                        controlsess_df = df_clean.iloc[idx_beg:idx_beg + n_trials]\n",
    "                        # grab target values from this dataframe\n",
    "                        controltarget_vals_list = list(controlsess_df[kwargs['target']].to_numpy())\n",
    "                        control_mask = mask\n",
    "\n",
    "                    save_predictions = kwargs.get('save_predictions_pseudo', kwargs['save_predictions'])\n",
    "\n",
    "                    # session for null dist\n",
    "                    ys_wmask = [controltarget_vals_list[m] for m in np.squeeze(np.where(control_mask))]\n",
    "                    Xs_wmask = [Xs[m] for m in np.squeeze(np.where(control_mask))]\n",
    "\n",
    "                if sample_pseudo_count > 1:\n",
    "                    print(f'sampled pseudo sessions {sample_pseudo_count} times to ensure valid target')\n",
    "\n",
    "            else:\n",
    "                control_mask = mask\n",
    "                save_predictions = kwargs['save_predictions']\n",
    "\n",
    "                # original session\n",
    "                ys_wmask = [target_vals_list[m] for m in np.squeeze(np.where(mask))]\n",
    "                Xs_wmask = [Xs[m] for m in np.squeeze(np.where(mask))]\n",
    "\n",
    "                if kwargs['estimator'] == sklm.LogisticRegression and (not logisticreg_criteria(ys_wmask)):\n",
    "                    print(f'target failed logistic regression criteria for region {region} and pseudo_id {pseudo_id}')\n",
    "                    continue\n",
    "\n",
    "            for i_run in range(kwargs['n_runs']):\n",
    "\n",
    "                rng_seed = i_run\n",
    "\n",
    "                fit_result = decode_cv(\n",
    "                    ys=ys_wmask,\n",
    "                    Xs=Xs_wmask,\n",
    "                    estimator=kwargs['estimator'],\n",
    "                    use_openturns=kwargs['use_openturns'],\n",
    "                    target_distribution=target_distribution,\n",
    "                    balanced_continuous_target=kwargs['balanced_continuous_target'],\n",
    "                    estimator_kwargs=kwargs['estimator_kwargs'],\n",
    "                    hyperparam_grid=kwargs['hyperparam_grid'],\n",
    "                    save_binned=kwargs['save_binned'] if pseudo_id == -1 else False,\n",
    "                    save_predictions=save_predictions,\n",
    "                    shuffle=kwargs['shuffle'],\n",
    "                    balanced_weight=kwargs['balanced_weight'],\n",
    "                    rng_seed=rng_seed,\n",
    "                )\n",
    "                fit_result['mask'] = mask\n",
    "                fit_result['mask_trials_and_targets'] = [trials_mask, target_mask]\n",
    "                fit_result['mask_diagnostics'] = kwargs['trials_mask_diagnostics']\n",
    "                fit_result['df'] = trials_df if pseudo_id == -1 else controlsess_df\n",
    "                fit_result['pseudo_id'] = pseudo_id\n",
    "                fit_result['run_id'] = i_run\n",
    "                fit_result['cluster_uuids'] = cl_uuids_used\n",
    "                fit_results.append(fit_result)\n",
    "\n",
    "            filename = save_region_results(\n",
    "                    fit_result=fit_results,\n",
    "                    pseudo_id=pseudo_id,\n",
    "                    subject=metadata['subject'],\n",
    "                    eid=metadata['eid'],\n",
    "                    probe=metadata['probe_name'],\n",
    "                    region=region,\n",
    "                    n_units=n_units,\n",
    "                    save_path=save_path\n",
    "            )\n",
    "\n",
    "            filenames.append(filename)\n",
    "            \n",
    "    filenames_by_eids.update({eid: filenames})\n",
    "            \n",
    "    res = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'rb') as f:\n",
    "            res.append(pickle.load(f))\n",
    "\n",
    "    true_score = res[0][\"fit\"][0][\"scores_test_full\"]\n",
    "    null_median = np.median([null[\"fit\"][0][\"scores_test_full\"] for null in res[1:]])\n",
    "    adj_acc = true_score - null_median\n",
    "    metrics_by_eids.update({eid: [true_score, null_median, adj_acc]})\n",
    "\n",
    "    print(f'Finished eid: {metadata[\"eid\"]}')\n",
    "    print(metrics_by_eids)\n",
    "    np.save(res_path, metrics_by_eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f3c66-f124-46c2-9284-7e6bb081822e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e68596-cb6d-4f48-b08d-b7a2ef5d60bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
